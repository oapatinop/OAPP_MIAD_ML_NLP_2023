{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller: Construcción e implementación de modelos Bagging, Random Forest y XGBoost\n",
    "\n",
    "En este taller podrán poner en práctica sus conocimientos sobre la construcción e implementación de modelos de Bagging, Random Forest y XGBoost. El taller está constituido por 8 puntos, en los cuales deberan seguir las intrucciones de cada numeral para su desarrollo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos predicción precio de automóviles\n",
    "\n",
    "En este taller se usará el conjunto de datos de Car Listings de Kaggle donde cada observación representa el precio de un automóvil teniendo en cuenta distintas variables como año, marca, modelo, entre otras. El objetivo es predecir el precio del automóvil. Para más detalles puede visitar el siguiente enlace: [datos](https://www.kaggle.com/jpayne/852k-used-car-listings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21995</td>\n",
       "      <td>2014</td>\n",
       "      <td>6480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13995</td>\n",
       "      <td>2014</td>\n",
       "      <td>39972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>17941</td>\n",
       "      <td>2016</td>\n",
       "      <td>18989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>12493</td>\n",
       "      <td>2014</td>\n",
       "      <td>51330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>7994</td>\n",
       "      <td>2007</td>\n",
       "      <td>116065</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  \\\n",
       "7    21995  2014     6480        0           0            0         1   \n",
       "11   13995  2014    39972        0           0            0         0   \n",
       "167  17941  2016    18989        0           0            0         0   \n",
       "225  12493  2014    51330        0           0            0         1   \n",
       "270   7994  2007   116065        0           1            0         0   \n",
       "\n",
       "     M_CamryLE  M_CamrySE  M_CamryXLE  \n",
       "7            0          0           0  \n",
       "11           1          0           0  \n",
       "167          0          1           0  \n",
       "225          0          0           0  \n",
       "270          0          0           0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importación de librerías\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Lectura de la información de archivo .csv\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/datasets/dataTrain_carListings.zip')\n",
    "\n",
    "# Preprocesamiento de datos para el taller\n",
    "data = data.loc[data['Model'].str.contains('Camry')].drop(['Make', 'State'], axis=1)\n",
    "data = data.join(pd.get_dummies(data['Model'], prefix='M'))\n",
    "data = data.drop(['Model'], axis=1)\n",
    "\n",
    "# Visualización dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y variable de interés (y)\n",
    "y = data['Price']\n",
    "X = data.drop(['Price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de datos en set de entrenamiento y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 1 - Árbol de decisión manual\n",
    "\n",
    "En la celda 1 creen un árbol de decisión **manualmente**  que considere los set de entrenamiento y test definidos anteriormente y presenten el RMSE y MAE del modelo en el set de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1\n",
    "def best_split(X, y, num_pct=10):\n",
    "    features = range(X.shape[1])\n",
    "    best_split = [0, 0, 0]  # j, split, mse\n",
    "    # Para todas las varibles \n",
    "    for j in features:\n",
    "        splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "        \n",
    "        # Para cada partición\n",
    "        i=0\n",
    "        for split in splits:\n",
    "            filter_l = X.iloc[:,j] < split\n",
    "            y_l = y.loc[filter_l]\n",
    "            y_r = y.loc[~filter_l]\n",
    "            mse = np.average(np.square(y_l.mean()-y))\n",
    "            if i==0:\n",
    "                best_split = [j, split, mse]\n",
    "            elif (mse < best_split[2]):\n",
    "                best_split = [j, split, mse]\n",
    "            i+=1\n",
    "    \n",
    "    return best_split\n",
    "\n",
    "def tree_grow(X, y, level=0, max_depth=None, num_pct=10):\n",
    "    \n",
    "    # Si solo es una observación\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=y.mean(), level=level, split=-1, n_samples=1,mse=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calcular la mejor división\n",
    "    j, split, mse = best_split(X, y, num_pct)\n",
    "    \n",
    "    # Guardar el árbol y estimar la predicción\n",
    "    y_pred = int(y.mean()) \n",
    "    y_prob = (y.sum()+1) / (y.shape[0]+2)  # Corrección Laplace \n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0],mse=mse)\n",
    "    # Revisar el criterio de parada \n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    # Continuar creando la partición\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "\n",
    "    # Siguiente iteración para cada partición\n",
    "    \n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, max_depth=max_depth, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, max_depth=max_depth, num_pct=num_pct)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "def tree_predict(X, tree, proba=False):\n",
    "    \n",
    "    predicted = np.ones(X.shape[0])\n",
    "\n",
    "    # Revisar si es el nodo final\n",
    "    if tree['split'] == -1:\n",
    "        if not proba:\n",
    "            predicted = predicted * tree['y_pred']\n",
    "        else:\n",
    "            predicted = predicted * tree['y_prob']\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        j, split = tree['split']\n",
    "        filter_l = (X.iloc[:, j] < split)\n",
    "        X_l = X.loc[filter_l]\n",
    "        X_r = X.loc[~filter_l]\n",
    "\n",
    "        if X_l.shape[0] == 0:  # Si el nodo izquierdo está vacio solo continua con el derecho \n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "        elif X_r.shape[0] == 0:  #  Si el nodo derecho está vacio solo continua con el izquierdo\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "        else:\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = tree_grow(X_train, y_train, level=0, max_depth=10, num_pct=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13135.,  8622., 17644., ..., 17644., 10882., 11367.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predTreeManual = tree_predict(X_test, tree)\n",
    "y_predTreeManual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2156.298895352172"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rmse_TreeManual = mean_squared_error(y_test, y_predTreeManual, squared=False)\n",
    "rmse_TreeManual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1586.6264434180139"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "mae_TreeManual = mae(y_test, y_predTreeManual)\n",
    "mae_TreeManual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 2 - Bagging manual\n",
    "\n",
    "En la celda 2 creen un modelo bagging **manualmente** con 10 árboles de clasificación y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257343</th>\n",
       "      <td>14980.0</td>\n",
       "      <td>13993.0</td>\n",
       "      <td>13649.0</td>\n",
       "      <td>13649.0</td>\n",
       "      <td>11788.0</td>\n",
       "      <td>13649.0</td>\n",
       "      <td>13993.0</td>\n",
       "      <td>13990.0</td>\n",
       "      <td>13990.0</td>\n",
       "      <td>13993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326011</th>\n",
       "      <td>6492.0</td>\n",
       "      <td>5995.0</td>\n",
       "      <td>5995.0</td>\n",
       "      <td>6987.0</td>\n",
       "      <td>5995.0</td>\n",
       "      <td>5995.0</td>\n",
       "      <td>5995.0</td>\n",
       "      <td>6987.0</td>\n",
       "      <td>5995.0</td>\n",
       "      <td>5995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242354</th>\n",
       "      <td>16491.0</td>\n",
       "      <td>16995.0</td>\n",
       "      <td>16491.0</td>\n",
       "      <td>15997.0</td>\n",
       "      <td>15997.0</td>\n",
       "      <td>16491.0</td>\n",
       "      <td>17591.0</td>\n",
       "      <td>16995.0</td>\n",
       "      <td>17404.0</td>\n",
       "      <td>16491.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266376</th>\n",
       "      <td>21990.0</td>\n",
       "      <td>21990.0</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>21990.0</td>\n",
       "      <td>15900.0</td>\n",
       "      <td>21990.0</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>21990.0</td>\n",
       "      <td>15813.0</td>\n",
       "      <td>21990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396954</th>\n",
       "      <td>15988.0</td>\n",
       "      <td>16951.0</td>\n",
       "      <td>15988.0</td>\n",
       "      <td>15988.0</td>\n",
       "      <td>15988.0</td>\n",
       "      <td>17900.0</td>\n",
       "      <td>16951.0</td>\n",
       "      <td>16951.0</td>\n",
       "      <td>15988.0</td>\n",
       "      <td>15988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144298</th>\n",
       "      <td>13836.0</td>\n",
       "      <td>14800.0</td>\n",
       "      <td>14800.0</td>\n",
       "      <td>14800.0</td>\n",
       "      <td>14800.0</td>\n",
       "      <td>14681.0</td>\n",
       "      <td>14800.0</td>\n",
       "      <td>14800.0</td>\n",
       "      <td>13836.0</td>\n",
       "      <td>13836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364521</th>\n",
       "      <td>15999.0</td>\n",
       "      <td>14995.0</td>\n",
       "      <td>15999.0</td>\n",
       "      <td>16900.0</td>\n",
       "      <td>15999.0</td>\n",
       "      <td>15999.0</td>\n",
       "      <td>17300.0</td>\n",
       "      <td>15999.0</td>\n",
       "      <td>16900.0</td>\n",
       "      <td>15000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120072</th>\n",
       "      <td>23533.0</td>\n",
       "      <td>23533.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>17700.0</td>\n",
       "      <td>17700.0</td>\n",
       "      <td>23533.0</td>\n",
       "      <td>17700.0</td>\n",
       "      <td>23533.0</td>\n",
       "      <td>23533.0</td>\n",
       "      <td>20000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99878</th>\n",
       "      <td>12989.0</td>\n",
       "      <td>12995.0</td>\n",
       "      <td>12989.0</td>\n",
       "      <td>12995.0</td>\n",
       "      <td>12991.0</td>\n",
       "      <td>12991.0</td>\n",
       "      <td>10995.0</td>\n",
       "      <td>12991.0</td>\n",
       "      <td>12991.0</td>\n",
       "      <td>12893.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387162</th>\n",
       "      <td>10991.0</td>\n",
       "      <td>11314.0</td>\n",
       "      <td>12999.0</td>\n",
       "      <td>12995.0</td>\n",
       "      <td>9995.0</td>\n",
       "      <td>11995.0</td>\n",
       "      <td>11985.0</td>\n",
       "      <td>10991.0</td>\n",
       "      <td>11314.0</td>\n",
       "      <td>14995.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3464 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1        2        3        4        5        6  \\\n",
       "257343  14980.0  13993.0  13649.0  13649.0  11788.0  13649.0  13993.0   \n",
       "326011   6492.0   5995.0   5995.0   6987.0   5995.0   5995.0   5995.0   \n",
       "242354  16491.0  16995.0  16491.0  15997.0  15997.0  16491.0  17591.0   \n",
       "266376  21990.0  21990.0  22500.0  21990.0  15900.0  21990.0  22500.0   \n",
       "396954  15988.0  16951.0  15988.0  15988.0  15988.0  17900.0  16951.0   \n",
       "...         ...      ...      ...      ...      ...      ...      ...   \n",
       "144298  13836.0  14800.0  14800.0  14800.0  14800.0  14681.0  14800.0   \n",
       "364521  15999.0  14995.0  15999.0  16900.0  15999.0  15999.0  17300.0   \n",
       "120072  23533.0  23533.0  20000.0  17700.0  17700.0  23533.0  17700.0   \n",
       "99878   12989.0  12995.0  12989.0  12995.0  12991.0  12991.0  10995.0   \n",
       "387162  10991.0  11314.0  12999.0  12995.0   9995.0  11995.0  11985.0   \n",
       "\n",
       "              7        8        9  \n",
       "257343  13990.0  13990.0  13993.0  \n",
       "326011   6987.0   5995.0   5995.0  \n",
       "242354  16995.0  17404.0  16491.0  \n",
       "266376  21990.0  15813.0  21990.0  \n",
       "396954  16951.0  15988.0  15988.0  \n",
       "...         ...      ...      ...  \n",
       "144298  14800.0  13836.0  13836.0  \n",
       "364521  15999.0  16900.0  15000.0  \n",
       "120072  23533.0  23533.0  20000.0  \n",
       "99878   12991.0  12991.0  12893.0  \n",
       "387162  10991.0  11314.0  14995.0  \n",
       "\n",
       "[3464 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 2\n",
    "# Creación de 10 muestras de bootstrap para los 10 árboles\n",
    "np.random.seed(123)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "n_B = 10\n",
    "\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(1, n_B +1 )]\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "treereg = DecisionTreeRegressor(max_depth=None, random_state=123)\n",
    "y_pred = pd.DataFrame(index=y_test.index, columns=[list(range(n_B))])\n",
    "\n",
    "for i, sample in enumerate(samples):\n",
    "    X2_train = X_train.iloc[sample,:]\n",
    "    y2_train = y_train.iloc[sample]\n",
    "    treereg.fit(X2_train, y2_train)\n",
    "    y_pred.iloc[:,i] = treereg.predict(X_test)\n",
    "    \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árbol  0 tiene un rmse:  2141.613353645869\n",
      "Árbol  1 tiene un rmse:  2136.3519863123465\n",
      "Árbol  2 tiene un rmse:  2122.718759132052\n",
      "Árbol  3 tiene un rmse:  2087.278992468617\n",
      "Árbol  4 tiene un rmse:  2168.518742842026\n",
      "Árbol  5 tiene un rmse:  2113.8811455834793\n",
      "Árbol  6 tiene un rmse:  2127.933470769012\n",
      "Árbol  7 tiene un rmse:  2184.414847251443\n",
      "Árbol  8 tiene un rmse:  2138.1071697514985\n",
      "Árbol  9 tiene un rmse:  2132.097520859104\n"
     ]
    }
   ],
   "source": [
    "# Desempeño de cada árbol\n",
    "for i in range(n_B):\n",
    "    print('Árbol ', i, 'tiene un rmse: ', (mean_squared_error(y_pred.iloc[:,i], y_test, squared=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Promediamos las predicciones\n",
    "y_predBaggingManual = y_pred.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1796.4355868399332"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_BaggingManual = mean_squared_error(y_test, y_predBaggingManual, squared=False)\n",
    "rmse_BaggingManual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1340.0160739030025"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_BaggingManual = mae(y_test, y_predBaggingManual)\n",
    "mae_BaggingManual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DESEMPEÑO DEL MODELO**\n",
    "\n",
    "Encontramos que en general en comparación con el modelo de un solo árbol de decisión realizando un ensamblaje por Bagging de 10 árboles mejora notablemente el desempeño de la predicción, donde vemos que la comparación del rmse es de 1796 para el Bagging y 2156 para un modelo con solo un árbol.\n",
    "\n",
    "Por otro lado el mean absolute error mejor de 1586 de un solo árbol de decisión a 1340 para el modelo de bagging, para este caso se demuestra como este ensamble de 10 árboles mejora en rendimiento a los resultados de un solo árbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 3 - Bagging con librería\n",
    "\n",
    "En la celda 3, con la librería sklearn, entrenen un modelo bagging con 10 árboles de clasificación y el parámetro `max_features` igual a `log(n_features)` y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13011.8,  6612.8, 16692.6, ..., 22596.4, 12990.6, 11969.1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 3\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "bagreg = BaggingRegressor(DecisionTreeRegressor(max_features='log2'), n_estimators=10, \n",
    "                          bootstrap=True, oob_score=True, random_state=1)\n",
    "bagreg.fit(X_train, y_train)\n",
    "y_predBagging = bagreg.predict(X_test)\n",
    "y_predBagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1824.7000069648657"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_Bagging = mean_squared_error(y_test, y_predBagging, squared=False)\n",
    "rmse_Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1361.8777493561897"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_Bagging = mae(y_test, y_predBagging)\n",
    "mae_Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 4 - Random forest con librería\n",
    "\n",
    "En la celda 4, usando la librería sklearn entrenen un modelo de Randon Forest para clasificación  y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13334.53,  6622.16, 16445.36, ..., 21396.13, 12952.33, 11809.75])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 4\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Definición de modelo Random Forest para un problema de clasificación\n",
    "regRF = RandomForestRegressor()\n",
    "regRF.fit(X_train, y_train)\n",
    "y_predRF = regRF.predict(X_test)\n",
    "y_predRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1757.4790838730512"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_RF = mean_squared_error(y_test, y_predRF, squared=False)\n",
    "rmse_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309.2108310607712"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_RF = mae(y_test, y_predRF)\n",
    "mae_RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 5 - Calibración de parámetros Random forest\n",
    "\n",
    "En la celda 5, calibren los parámetros max_depth, max_features y n_estimators del modelo de Randon Forest para clasificación, comenten sobre el desempeño del modelo y describan cómo cada parámetro afecta el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 6 - XGBoost con librería\n",
    "\n",
    "En la celda 6 implementen un modelo XGBoost de clasificación con la librería sklearn y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 7 - Calibración de parámetros XGBoost\n",
    "\n",
    "En la celda 7 calibren los parámetros learning rate, gamma y colsample_bytree del modelo XGBoost para clasificación, comenten sobre el desempeño del modelo y describan cómo cada parámetro afecta el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 8 - Comparación y análisis de resultados\n",
    "En la celda 8 comparen los resultados obtenidos de los diferentes modelos (random forest y XGBoost) y comenten las ventajas del mejor modelo y las desventajas del modelo con el menor desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 8\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
